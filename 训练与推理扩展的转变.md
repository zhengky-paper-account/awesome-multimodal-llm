1.训练扩展定律

依赖训练数据量、模型规模和计算资源的增加提高大模型性能。随着高质量预训练语料的逐渐枯竭，这种“训练扩展”的方式已接近饱和点，性能提升变得困难。

2.推理扩展

在推理（测试）阶段引入更多计算成本的方法。

2.1 重复采样与选择：例如 best-of-n 或 多数投票，通过多次生成答案并选择最优的一个来提高准确率（Brown et al., 2024b、Wu et al., 2024a）。

2.2 自我修正：LLMs能够根据内部（Madaan et al., 2024）或外部（Jiang et al., 2023b）反馈来优化自身生成的答案（Kamoi et al., 2024、Pan et al., 2024）。

·概率论模型解释自我修正

（1）单个问题在每次自校正迭代中正确概率的变化

```math
P(a_{i,t})
=
P(a_{i,t-1}) P(a_{i,t} \mid a_{i,t-1})
+
[1 - P(a_{i,t-1})]
P(a_{i,t} \mid \neg a_{i,t-1})


(2)假设 P(a_{i,t} \mid a_{i,t-1}) = P^{con}_i 和 P(a_{i,t} \mid \neg a_{i,t-1}) = P^{cri}_i 是与轮次 t 无关的常数，代入公式 (1) 并整理：

P(a_{i,t})
= (P^{con}_i - P^{cri}_i) P(a_{i,t-1})
+ P^{cri}_i
\quad 
```
