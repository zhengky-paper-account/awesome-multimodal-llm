

一、传统基于 Transformer 的 MoE
1.基本概念
（1）目的：不破坏 Transformer 并行性的情况下扩展参数规模，适用于需要提高效率和规模的领域。
（2）路由粒度: 路由器通常根据每个输入的 token 来决定将其路由到哪个或哪几个专家
（3）专家分化：训练过程中自发地学习如何最高效地分配和组织知识
（4）激活模式 : 采用稀疏激活。对于每个 token，只有一小部分（例如，1 个或 2 个）专家会被激活并进行计算，其余专家保持非活跃状态，从而节省计算资源
2.发展
（1）
3.检验方法
3.1性能分析
（1）高效性：与专家参数和计算量是 本方案 1.5/2 倍的更大 GShard 模型对比，比同样强大的稠密架构具有显著的计算成本优势。
（2）是否能达到性能上限：与总参数量和本方案一样的稠密模型对比，如果一个 MoE 模型能够达到或接近这个稠密模型的性能，就意味着 MoE 架构（尽管通过稀疏激活来节省计算）并没有因为其稀疏性而牺牲其整体的模型容量。它能够充分利用其庞大的总参数量所带来的潜在知识表达能力。
（3）是否有与当前主流模型相媲美的性能、更少的算力成本、更大潜在能力：与主流 7B 稠密模型对比性能水平、每次前向传播的实际计算成本、总参数量和激活参数量

3.2专家专业化分析
（1）冗余度检验：如果一个模型中的专家是高度专业化且不可替代的，那么当你移除那些被路由器认为“最重要”的专家时，模型性能应该会显著下降。反之，如果专家之间存在大量冗余，那么即使移除了顶层专家，其他专家也能弥补损失，导致性能下降不那么剧烈。

（2）知识获取效率检验：通过减少激活的路由专家数量，观察是否仍能保持与基线 MoE 模型相当的性能。如果可以，则表明本方案的专家（即使是数量更少的激活专家）也能更准确、高效地获取所需知识，因为它们的分化和专业化程度更高。

3.3大规模扩展
证明本架构在更大规模参数和训练数据下依然有效，并能实现显著的计算效率。

二、功能性专家混合
（1）目的：通过将不同模式抽象成不同专家，实现解耦和路由加权融合，适用于需要可解释性和对数据复杂内在结构理解的领域。
（2）路由粒度：
（3）专家分化：通过设计不同的损失函数约束达到专家分化
